<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="../../css/aosa.css" type="text/css">
    <title>500 Lines or Less: A Flow Shop Scheduler</title>
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
          tex2jax: {
            inlineMath: [['$','$'], ['\\(','\\)']],
            displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
          },
        });
    </script>
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  </head>
  <body>

    <div class="titlebox">
      <h1>A Flow Shop Scheduler</h1>
      <p class="author">Christian Muise</p>
    </div>

    <p><em><a href="http://haz.ca">Dr. Christian Muise</a> is a Research Fellow with the <a href="http://groups.csail.mit.edu/mers/">MERS group</a> at <a href="http://www.csail.mit.edu/">MIT's CSAIL</a>. He is interested in a variety of topics including AI, data-driven projects, mapping, graph theory, and data visualization, as well as celtic music, carving, soccer, and coffee.</em></p>

<h2 id="a-flow-shop-scheduler">A Flow Shop Scheduler</h2>

<p><em>Flow shop scheduling</em> is one of the most challenging and well-studied problems in operations research. Like many challenging optimization problems, finding the best solution is just not possible for problems of a practical size. In this chapter we consider the implementation of a flow shop scheduling solver that uses a technique called <em>local search</em>. Local search allows us to find a solution that is &quot;pretty good&quot; when finding the best solution isn't possible. The solver will try and find new solutions to the problem for a given amount of time, and finish by returning the best solution found.</p>

<p>The idea behind local search is to improve an existing solution heuristically by considering similar solutions that may be a little better. The solver uses a variety of strategies to (1) try and find similar solutions, and (2) choose one that is promising to explore next. The implementation is written in Python, and has no external requirements. By leveraging some of Python's lesser-known functionality, the solver dynamically changes its search strategy during the solving process based on which strategies work well.</p>

<p>First, we provide some background material on the flow shop scheduling problem and local search techniques. We then look in detail at the general solver code and the various heuristics and neighbourhood selection strategies that we use. Next we consider the dynamic strategy selection that the solver uses to tie everything together. Finally, we conclude with a summary of the project and some lessons learned through the implementation process.</p>

<h2 id="background">Background</h2>

<h3 id="flow-shop-scheduling">Flow Shop Scheduling</h3>

<p>The flow shop scheduling problem is an optimization problem in which we must determine the processing time for various tasks in a job in order to schedule the tasks to minimize the total time it takes to complete the job. Take, for example, a car manufacturer with an assembly line where each part of the car is completed in sequence on different machines. Different orders may have custom requirements, making the task of painting the body, for example, vary from one car to the next. In our example, each car is a new <em>job</em> and each part for the car is called a <em>task</em>. Every job will have the same sequence of tasks to complete.</p>

<p>The objective in flow shop scheduling is to minimize the total time it takes to process all of the tasks from every job to completion. (Typically, this total time is referred to as the <em>makespan</em>.) This problem has many applications, but is most related to optimizing production facilities.</p>

<p>Every flow shop problem consists of <span class="math">\(n\)</span> machines and <span class="math">\(m\)</span> jobs. In our car example, there will be <span class="math">\(n\)</span> stations to work on the car and <span class="math">\(m\)</span> cars to make in total. Each job is made up of exactly <span class="math">\(n\)</span> tasks, and we can assume that the <span class="math">\(i\)</span>-th task of a job must use machine <span class="math">\(i\)</span> and requires a predetermined amount of processing time: <span class="math">\(p(j,i)\)</span> is the processing time for the <span class="math">\(i\)</span>th task of job <span class="math">\(j\)</span>. Further, the order of the tasks for any given job should follow the order of the machines available; for a given job, task <span class="math">\(i\)</span> must be completed prior to the start of task <span class="math">\(i+1\)</span>. In our car example, we wouldn't want to start painting the car before the frame was assembled. The final restriction is that no two tasks can be processed on a machine simultaneously.</p>

<p>Because the order of tasks within a job is predetermined, a solution to the flow shop scheduling problem can be represented as a permutation of the jobs. The order of jobs processed on a machine will be the same for every machine, and given a permutation, a task for machine <span class="math">\(i\)</span> in job <span class="math">\(j\)</span> is scheduled to be the latest of the following two possibilities:</p>

<ol style="list-style-type: decimal">
<li><p>The completion of the task for machine <span class="math">\(i\)</span> in job <span class="math">\(j-1\)</span> (i.e., the most recent task on the same machine), or</p></li>
<li><p>The completion of the task for machine <span class="math">\(i-1\)</span> in job <span class="math">\(j\)</span> (i.e., the most recent task on the same job)</p></li>
</ol>

<p>Because we select the maximum of these two values, idle time for either machine <span class="math">\(i\)</span> or job <span class="math">\(j\)</span> will be created. It is this idle time that we ultimately want to minimize, as it will push the total makespan to be larger.</p>

<p>Due to the simple form of the problem, any permutation of jobs is a valid solution, and the optimal solution will correspond to <em>some</em> permutation. Thus, we search for improved solutions by changing the permutation of jobs and measuring the corresponding makespan. In what follows, we refer to a permutation of the jobs as a <em>candidate</em>.</p>

<p>Let's consider a simple example with two jobs and two machines. The first job has tasks <span class="math">\(\mathbf{A}\)</span> and <span class="math">\(\mathbf{B}\)</span>, which take 1 and 2 minutes to complete respectively. The second job has tasks <span class="math">\(\mathbf{C}\)</span> and <span class="math">\(\mathbf{D}\)</span>, which take 2 and 1 minutes to complete respectively. Recall that <span class="math">\(\mathbf{A}\)</span> must come before <span class="math">\(\mathbf{B}\)</span> and <span class="math">\(\mathbf{C}\)</span> must come before <span class="math">\(\mathbf{D}\)</span>. Because there are two jobs, we have just two permutations to consider. If we order job 2 before job 1, the makespan is 5 (<a href="#figure-9.1">Figure 9.1</a>); on the other hand, if we order job 1 before job 2, the makespan is only 4 (<a href="#figure-9.2">Figure 9.2</a>).</p>

<div class="center figure">
<a name="figure-9.1"></a><img src="flow-shop-images/example1.png" alt="Figure 9.1 - Flow Shop Example 1" title="Figure 9.1 - Flow Shop Example 1" />
</div>

<p class="center figcaption">
<small>Figure 9.1 - Flow Shop Example 1</small>
</p>

<div class="center figure">
<a name="figure-9.2"></a><img src="flow-shop-images/example2.png" alt="Figure 9.2 - Flow Shop Example 2" title="Figure 9.2 - Flow Shop Example 2" />
</div>

<p class="center figcaption">
<small>Figure 9.2 - Flow Shop Example 2</small>
</p>

<p>Notice that there is no budge room to push any of the tasks earlier. A guiding principle for a good permutation is to minimize the time in which any machine is left without a task to process.</p>

<h3 id="local-search">Local Search</h3>

<p>Local search is a strategy for solving optimization problems when the optimal solution is too hard to compute. Intuitively, it moves from one solution that seems pretty good to another solution that seems even better. Rather than considering every possible solution as a candidate to focus on next, we define what is known as a <em>neighbourhood</em>: the set of solutions considered to be similar to the current solution. Because any permutation of jobs is a valid solution, we can view any mechanism that shuffles the jobs around as a local search procedure (this is in fact what we do below).</p>

<p>To use local search formally, we must answer a few questions:</p>

<ol style="list-style-type: decimal">
<li>What solution should we start with?</li>
<li>Given a solution, what are the neighbouring solutions that we should consider?</li>
<li>Given the set of candidate neighbours, which one should we consider moving to next?</li>
</ol>

<p>The following three sections address these questions in turn.</p>

<h2 id="general-solver">General Solver</h2>

<p>In this section we provide the general framework for the flow shop scheduler. To begin, we have the necessary Python imports and the settings for the solver:</p>

<pre class="sourceCode python"><code class="sourceCode python"><span class="ch">import</span> sys, os, time, random

<span class="ch">from</span> functools <span class="ch">import</span> partial
<span class="ch">from</span> collections <span class="ch">import</span> namedtuple
<span class="ch">from</span> itertools <span class="ch">import</span> product

<span class="ch">import</span> neighbourhood <span class="ch">as</span> neigh
<span class="ch">import</span> heuristics <span class="ch">as</span> heur

<span class="co">##############</span>
<span class="co">## Settings ##</span>
<span class="co">##############</span>
TIME_LIMIT = <span class="fl">300.0</span> <span class="co"># Time (in seconds) to run the solver</span>
TIME_INCREMENT = <span class="fl">13.0</span> <span class="co"># Time (in seconds) in between heuristic measurements</span>
DEBUG_SWITCH = <span class="ot">False</span> <span class="co"># Displays intermediate heuristic info when True</span>
MAX_LNS_NEIGHBOURHOODS = <span class="dv">1000</span> <span class="co"># Maximum number of neighbours to explore in LNS</span></code></pre>

<p>There are two settings that should be explained further. The <code>TIME_INCREMENT</code> setting will be used as part of the dynamic strategy selection, and the <code>MAX_LNS_NEIGHBOURHOODS</code> setting will be used as part of the neighbourhood selection strategy. Both are described in more detail below.</p>

<p>These settings could be exposed to the user as command line parameters, but at this stage we instead provide the input data as parameters to the program. The input problem—a problem from the Taillard benchmark set—is assumed to be in a standard format for flow shop scheduling. The following code is used as the <code>__main__</code> method for the solver file, and calls the appropriate functions based on the number of parameters input to the program:</p>

<pre class="sourceCode python"><code class="sourceCode python"><span class="kw">if</span> <span class="ot">__name__</span> == <span class="st">&#39;__main__&#39;</span>:

    <span class="kw">if</span> <span class="dt">len</span>(sys.argv) == <span class="dv">2</span>:
        data = parse_problem(sys.argv[<span class="dv">1</span>], <span class="dv">0</span>)
    <span class="kw">elif</span> <span class="dt">len</span>(sys.argv) == <span class="dv">3</span>:
        data = parse_problem(sys.argv[<span class="dv">1</span>], <span class="dt">int</span>(sys.argv[<span class="dv">2</span>]))
    <span class="kw">else</span>:
        <span class="dt">print</span> <span class="st">&quot;</span><span class="ch">\n</span><span class="st">Usage: python flow.py &lt;Taillard problem file&gt; [&lt;instance number&gt;]</span><span class="ch">\n</span><span class="st">&quot;</span>
        sys.exit(<span class="dv">0</span>)

    (perm, ms) = solve(data)
    print_solution(data, perm)</code></pre>

<p>We will describe the parsing of Taillard problem files shortly. (The files are <a href="http://mistic.heig-vd.ch/taillard/problemes.dir/ordonnancement.dir/ordonnancement.html">available online</a>.)</p>

<p>The <code>solve</code> method expects the <code>data</code> variable to be a list of integers containing the activity durations for each job. The <code>solve</code> method starts by initializing a global set of strategies (to be described below). The key is that we use <code>strat_*</code> variables to maintain statistics on each of the strategies. This aids in selecting the strategy dynamically during the solving process.</p>

<pre class="sourceCode python"><code class="sourceCode python"><span class="kw">def</span> solve(data):
    <span class="co">&quot;&quot;&quot;Solves an instance of the flow shop scheduling problem&quot;&quot;&quot;</span>

    <span class="co"># We initialize the strategies here to avoid cyclic import issues</span>
    initialize_strategies()
    <span class="kw">global</span> STRATEGIES

    <span class="co"># Record the following for each strategy:</span>
    <span class="co">#  improvements: The amount a solution was improved by this strategy</span>
    <span class="co">#  time_spent: The amount of time spent on the strategy</span>
    <span class="co">#  weights: The weights that correspond to how good a strategy is</span>
    <span class="co">#  usage: The number of times we use a strategy</span>
    strat_improvements = {strategy: <span class="dv">0</span> <span class="kw">for</span> strategy in STRATEGIES}
    strat_time_spent = {strategy: <span class="dv">0</span> <span class="kw">for</span> strategy in STRATEGIES}
    strat_weights = {strategy: <span class="dv">1</span> <span class="kw">for</span> strategy in STRATEGIES}
    strat_usage = {strategy: <span class="dv">0</span> <span class="kw">for</span> strategy in STRATEGIES}</code></pre>

<p>One appealing feature of the flow shop scheduling problem is that <em>every</em> permutation is a valid solution, and at least one will have the optimal makespan (though many will have horrible makespans). Thankfully, this allows us to forgo checking that we stay within the space of feasible solutions when going from one permutation to another—everything is feasible!</p>

<p>However, to start a local search in the space of permutations, we must have an initial permutation. To keep things simple, we seed our local search by shuffling the list of jobs randomly:</p>

<pre class="sourceCode python"><code class="sourceCode python">    <span class="co"># Start with a random permutation of the jobs</span>
    perm = <span class="dt">range</span>(<span class="dt">len</span>(data))
    random.shuffle(perm)</code></pre>

<p>Next, we initialize the variables that allow us to keep track of the best permutation found so far, as well as the timing information for providing output. </p>

<pre class="sourceCode python"><code class="sourceCode python">    <span class="co"># Keep track of the best solution</span>
    best_make = makespan(data, perm)
    best_perm = perm
    res = best_make

    <span class="co"># Maintain statistics and timing for the iterations</span>
    iteration = <span class="dv">0</span>
    time_limit = time.time() + TIME_LIMIT
    time_last_switch = time.time()

    time_delta = TIME_LIMIT / <span class="dv">10</span>
    checkpoint = time.time() + time_delta
    percent_complete = <span class="dv">10</span>

    <span class="dt">print</span> <span class="st">&quot;</span><span class="ch">\n</span><span class="st">Solving...&quot;</span></code></pre>

<p>As this is a local search solver, we simply continue to try and improve solutions as long as the time limit has not been reached. We provide output indicating the progress of the solver and keep track of the number of iterations we have computed:</p>

<pre class="sourceCode python"><code class="sourceCode python">    <span class="kw">while</span> time.time() &lt; time_limit:

        <span class="kw">if</span> time.time() &gt; checkpoint:
            <span class="dt">print</span> <span class="st">&quot; </span><span class="ot">%d</span><span class="st"> </span><span class="ot">%%</span><span class="st">&quot;</span> % percent_complete
            percent_complete += <span class="dv">10</span>
            checkpoint += time_delta

        iteration += <span class="dv">1</span></code></pre>

<p>Below we describe how the strategy is picked, but for now it is sufficient to know that the strategy provides a <code>neighbourhood</code> function and a <code>heuristic</code> function. The former gives us a set of <em>next candidates</em> to consider while the latter chooses the <em>best candidate</em> from the set. From these functions, we have a new permutation (<code>perm</code>) and a new makespan result (<code>res</code>):</p>

<pre class="sourceCode python"><code class="sourceCode python">        <span class="co"># Heuristically choose the best strategy</span>
        strategy = pick_strategy(STRATEGIES, strat_weights)

        old_val = res
        old_time = time.time()

        <span class="co"># Use the current strategy&#39;s heuristic to pick the next permutation from</span>
        <span class="co"># the set of candidates generated by the strategy&#39;s neighbourhood</span>
        candidates = strategy.neighbourhood(data, perm)
        perm = strategy.heuristic(data, candidates)
        res = makespan(data, perm)</code></pre>

<p>The code for computing the makespan is quite simple: we can compute it from a permutation by evaluating when the final job completes. We will see below how <code>compile_solution</code> works, but for now it suffices to know that a 2D array is returned and the element at <code>[-1][-1]</code> corresponds to the start time of the final job in the schedule:</p>

<pre class="sourceCode python"><code class="sourceCode python"><span class="kw">def</span> makespan(data, perm):
    <span class="co">&quot;&quot;&quot;Computes the makespan of the provided solution&quot;&quot;&quot;</span>
    <span class="kw">return</span> compile_solution(data, perm)[-<span class="dv">1</span>][-<span class="dv">1</span>] + data[perm[-<span class="dv">1</span>]][-<span class="dv">1</span>]</code></pre>

<p>To help select a strategy, we keep statistics on (1) how much the strategy has improved the solution, (2) how much time the strategy has spent computing information, and (3) how many times the strategy was used. We also update the variables for the best permutation if we stumble upon a better solution:</p>

<pre class="sourceCode python"><code class="sourceCode python">        <span class="co"># Record the statistics on how the strategy did</span>
        strat_improvements[strategy] += res - old_val
        strat_time_spent[strategy] += time.time() - old_time
        strat_usage[strategy] += <span class="dv">1</span>

        <span class="kw">if</span> res &lt; best_make:
            best_make = res
            best_perm = perm[:]</code></pre>

<p>At regular intervals, the statistics for strategy use are updated. We removed the associated snippet for readability, and detail the code below. As a final step, once the while loop is complete (i.e., the time limit is reached) we output some statistics about the solving process and return the best permutation along with its makespan:</p>

<pre class="sourceCode python"><code class="sourceCode python">    <span class="dt">print</span> <span class="st">&quot; </span><span class="ot">%d</span><span class="st"> </span><span class="ot">%%</span><span class="ch">\n</span><span class="st">&quot;</span> % percent_complete
    <span class="dt">print</span> <span class="st">&quot;</span><span class="ch">\n</span><span class="st">Went through </span><span class="ot">%d</span><span class="st"> iterations.&quot;</span> % iteration

    <span class="dt">print</span> <span class="st">&quot;</span><span class="ch">\n</span><span class="st">(usage) Strategy:&quot;</span>
    results = <span class="dt">sorted</span>([(strat_weights[STRATEGIES[i]], i)
                      <span class="kw">for</span> i in <span class="dt">range</span>(<span class="dt">len</span>(STRATEGIES))], reverse=<span class="ot">True</span>)
    <span class="kw">for</span> (w, i) in results:
        <span class="dt">print</span> <span class="st">&quot;(</span><span class="ot">%d</span><span class="st">) </span><span class="ch">\t</span><span class="ot">%s</span><span class="st">&quot;</span> % (strat_usage[STRATEGIES[i]], STRATEGIES[i].name)

    <span class="kw">return</span> (best_perm, best_make)</code></pre>

<h3 id="parsing-problems">Parsing Problems</h3>

<p>As input to the parsing procedure, we provide the file name where the input can be found and the example number that should be used. (Each file contains a number of instances.)</p>

<pre class="sourceCode python"><code class="sourceCode python"><span class="kw">def</span> parse_problem(filename, k=<span class="dv">1</span>):
    <span class="co">&quot;&quot;&quot;Parse the kth instance of a Taillard problem file</span>

<span class="co">    The Taillard problem files are a standard benchmark set for the problem</span>
<span class="co">    of flow shop scheduling. </span>

<span class="co">    print &quot;\nParsing...&quot;</span></code></pre>

<p>We start the parsing by reading in the file and identifying the line that separates each of the problem instances:</p>

<pre class="sourceCode python"><code class="sourceCode python">    <span class="kw">with</span> <span class="dt">open</span>(filename, <span class="st">&#39;r&#39;</span>) <span class="ch">as</span> f:
        <span class="co"># Identify the string that separates instances</span>
        problem_line = (<span class="st">&#39;/number of jobs, number of machines, initial seed, &#39;</span>
                        <span class="co">&#39;upper bound and lower bound :/&#39;</span>)

        <span class="co"># Strip spaces and newline characters from every line</span>
        lines = <span class="dt">map</span>(<span class="dt">str</span>.strip, f.readlines())</code></pre>

<p>To make locating the correct instance easier, we assume that lines will be separated by a '/' character. This allows us to split the file based on a common string that appears at the top of every instance, and adding a '/' character to the start of the first line allows the string processing below to work correctly regardless of the instance we choose. We also detect when a provided instance number is out of range given the collection of instances found in the file.</p>

<pre class="sourceCode python"><code class="sourceCode python">        <span class="co"># We prep the first line for later</span>
        lines[<span class="dv">0</span>] = <span class="st">&#39;/&#39;</span> + lines[<span class="dv">0</span>]

        <span class="co"># We also know &#39;/&#39; does not appear in the files, so we can use it as</span>
        <span class="co">#  a separator to find the right lines for the kth problem instance</span>
        <span class="kw">try</span>:
            lines = <span class="st">&#39;/&#39;</span>.join(lines).split(problem_line)[k].split(<span class="st">&#39;/&#39;</span>)[<span class="dv">2</span>:]
        <span class="kw">except</span> <span class="ot">IndexError</span>:
            max_instances = <span class="dt">len</span>(<span class="st">&#39;/&#39;</span>.join(lines).split(problem_line)) - <span class="dv">1</span>
            <span class="dt">print</span> <span class="st">&quot;</span><span class="ch">\n</span><span class="st">Error: Instance must be within 1 and </span><span class="ot">%d</span><span class="ch">\n</span><span class="st">&quot;</span> % max_instances
            sys.exit(<span class="dv">0</span>)</code></pre>

<p>We parse the data directly, converting the processing time of each task to an integer and storing it in a list. Finally, we zip the data to invert the rows and columns so that the format respects what is expected by the solving code above. (Every item in <code>data</code> should correspond to a particular job.)</p>

<pre class="sourceCode python"><code class="sourceCode python">        <span class="co"># Split every line based on spaces and convert each item to an int</span>
        data = [<span class="dt">map</span>(<span class="dt">int</span>, line.split()) <span class="kw">for</span> line in lines]

    <span class="co"># We return the zipped data to rotate the rows and columns, making each</span>
    <span class="co">#  item in data the durations of tasks for a particular job</span>
    <span class="kw">return</span> <span class="dt">zip</span>(*data)</code></pre>

<h3 id="compiling-solutions">Compiling Solutions</h3>

<p>A solution to the flow shop scheduling problem consists of precise timing for each task in every job. Because we represent a solution implicitly with a permutation of the jobs, we introduce the <code>compile_solution</code> function to convert a permutation to precise times. As input, the function takes in the data for the problem (giving us the duration of every task) and a permutation of jobs.</p>

<p>The function begins by initializing the data structure used to store the starting time for each task, and then including the tasks from the first job in the permutation.</p>

<pre class="sourceCode python"><code class="sourceCode python"><span class="kw">def</span> compile_solution(data, perm):
    <span class="co">&quot;&quot;&quot;Compiles a scheduling on the machines given a permutation of jobs&quot;&quot;&quot;</span>

    num_machines = <span class="dt">len</span>(data[<span class="dv">0</span>])

    <span class="co"># Note that using [[]] * m would be incorrect, as it would simply</span>
    <span class="co">#  copy the same list m times (as opposed to creating m distinct lists).</span>
    machine_times = [[] <span class="kw">for</span> _ in <span class="dt">range</span>(num_machines)]

    <span class="co"># Assign the initial job to the machines</span>
    machine_times[<span class="dv">0</span>].append(<span class="dv">0</span>)
    <span class="kw">for</span> mach in <span class="dt">range</span>(<span class="dv">1</span>,num_machines):
        <span class="co"># Start the next task in the job when the previous finishes</span>
        machine_times[mach].append(machine_times[mach<span class="dv">-1</span>][<span class="dv">0</span>] +
                                   data[perm[<span class="dv">0</span>]][mach<span class="dv">-1</span>])</code></pre>

<p>We then add all the tasks for the remaining jobs. The first task in a job will always start as soon as the first task in the previous job completes. For the remaining tasks, we schedule the job as early as possible: the maximum out of the completion time of the previous task in the same job and the completion time of the previous task on the same machine.</p>

<pre class="sourceCode python"><code class="sourceCode python">    <span class="co"># Assign the remaining jobs</span>
    <span class="kw">for</span> i in <span class="dt">range</span>(<span class="dv">1</span>, <span class="dt">len</span>(perm)):

        <span class="co"># The first machine never contains any idle time</span>
        job = perm[i]
        machine_times[<span class="dv">0</span>].append(machine_times[<span class="dv">0</span>][-<span class="dv">1</span>] + data[perm[i<span class="dv">-1</span>]][<span class="dv">0</span>])

        <span class="co"># For the remaining machines, the start time is the max of when the</span>
        <span class="co">#  previous task in the job completed, or when the current machine</span>
        <span class="co">#  completes the task for the previous job.</span>
        <span class="kw">for</span> mach in <span class="dt">range</span>(<span class="dv">1</span>, num_machines):
            machine_times[mach].append(<span class="dt">max</span>(
                machine_times[mach<span class="dv">-1</span>][i] + data[perm[i]][mach<span class="dv">-1</span>],
                machine_times[mach][i<span class="dv">-1</span>] + data[perm[i<span class="dv">-1</span>]][mach]))

    <span class="kw">return</span> machine_times</code></pre>

<h3 id="printing-solutions">Printing Solutions</h3>

<p>When the solving process is complete, the program outputs information about the solution in a compact form. Rather than providing the precise timing of every task for every job, we output the following pieces of information:</p>

<ol style="list-style-type: decimal">
<li>The permutation of jobs that yielded the best makespan</li>
<li>The computed makespan of the permutation</li>
<li>The start time, finish time, and idle time for every machine</li>
<li>The start time, finish time, and idle time for every job</li>
</ol>

<p>The start time for a job or machine corresponds to the start of the first task in the job or on the machine. Similarly, the finish time for a job or machine corresponds to the end of the final task in the job or on the machine. The idle time is the amount of slack in between tasks for a particular job or machine. Ideally we would like to reduce the amount of idle time, as it means the overall process time will be reduced as well.</p>

<p>The code to compile the solution (i.e., to compute the start times for every task) has already been discussed, and outputting the permutation and makespan are trivial:</p>

<pre class="sourceCode python"><code class="sourceCode python"><span class="kw">def</span> print_solution(data, perm):
    <span class="co">&quot;&quot;&quot;Prints statistics on the computed solution&quot;&quot;&quot;</span>

    sol = compile_solution(data, perm)

    <span class="dt">print</span> <span class="st">&quot;</span><span class="ch">\n</span><span class="st">Permutation: </span><span class="ot">%s</span><span class="ch">\n</span><span class="st">&quot;</span> % <span class="dt">str</span>([i<span class="dv">+1</span> <span class="kw">for</span> i in perm])

    <span class="dt">print</span> <span class="st">&quot;Makespan: </span><span class="ot">%d</span><span class="ch">\n</span><span class="st">&quot;</span> % makespan(data, perm)</code></pre>

<p>Next, we use the string formatting functionality in Python to print the table of start, end, and idle times for each of the machines and jobs. Note that the idle time for a job is the time from when the job started to its completion, minus the sum of the processing times for each task in the job. We compute the idle time for a machine in a similar fashion.</p>

<pre class="sourceCode python"><code class="sourceCode python">    row_format =<span class="st">&quot;{:&gt;15}&quot;</span> * <span class="dv">4</span>
    <span class="dt">print</span> row_format.<span class="dt">format</span>(<span class="st">&#39;Machine&#39;</span>, <span class="st">&#39;Start Time&#39;</span>, <span class="st">&#39;Finish Time&#39;</span>, <span class="st">&#39;Idle Time&#39;</span>)
    <span class="kw">for</span> mach in <span class="dt">range</span>(<span class="dt">len</span>(data[<span class="dv">0</span>])):
        finish_time = sol[mach][-<span class="dv">1</span>] + data[perm[-<span class="dv">1</span>]][mach]
        idle_time = (finish_time - sol[mach][<span class="dv">0</span>]) - <span class="dt">sum</span>([job[mach] <span class="kw">for</span> job in data])
        <span class="dt">print</span> row_format.<span class="dt">format</span>(mach<span class="dv">+1</span>, sol[mach][<span class="dv">0</span>], finish_time, idle_time)

    results = []
    <span class="kw">for</span> i in <span class="dt">range</span>(<span class="dt">len</span>(data)):
        finish_time = sol[-<span class="dv">1</span>][i] + data[perm[i]][-<span class="dv">1</span>]
        idle_time = (finish_time - sol[<span class="dv">0</span>][i]) - <span class="dt">sum</span>([time <span class="kw">for</span> time in data[perm[i]]])
        results.append((perm[i]+<span class="dv">1</span>, sol[<span class="dv">0</span>][i], finish_time, idle_time))

    <span class="dt">print</span> <span class="st">&quot;</span><span class="ch">\n</span><span class="st">&quot;</span>
    <span class="dt">print</span> row_format.<span class="dt">format</span>(<span class="st">&#39;Job&#39;</span>, <span class="st">&#39;Start Time&#39;</span>, <span class="st">&#39;Finish Time&#39;</span>, <span class="st">&#39;Idle Time&#39;</span>)
    <span class="kw">for</span> r in <span class="dt">sorted</span>(results):
        <span class="dt">print</span> row_format.<span class="dt">format</span>(*r)

    <span class="dt">print</span> <span class="st">&quot;</span><span class="ch">\n\n</span><span class="st">Note: Idle time does not include initial or final wait time.</span><span class="ch">\n</span><span class="st">&quot;</span></code></pre>

<h2 id="neighbourhoods">Neighbourhoods</h2>

<p>The idea behind local search is to move <em>locally</em> from one solution to other solutions nearby. We refer to the <em>neighbourhood</em> of a given solution as the other solutions that are local to it. In this section, we detail four potential neighbourhoods, each of increasing complexity.</p>

<p>The first neighbourhood produces a given number of random permutations. This neighbourhood does not even consider the solution that we begin with, and so the term &quot;neighbourhood&quot; stretches the truth. However, including some randomness in the search is good practice, as it promotes exploration of the search space.</p>

<pre class="sourceCode python"><code class="sourceCode python"><span class="kw">def</span> neighbours_random(data, perm, num = <span class="dv">1</span>):
    <span class="co"># Returns &lt;num&gt; random job permutations, including the current one</span>
    candidates = [perm]
    <span class="kw">for</span> i in <span class="dt">range</span>(num):
        candidate = perm[:]
        random.shuffle(candidate)
        candidates.append(candidate)
    <span class="kw">return</span> candidates</code></pre>

<p>For the next neighbourhood, we consider swapping any two jobs in the permutation. By using the <code>combinations</code> function from the <code>itertools</code> package, we can easily iterate through every pair of indices and create a new permutation that corresponds to swapping the jobs located at each index. In a sense, this neighbourhood creates permutations that are very similar to the one we began with.</p>

<pre class="sourceCode python"><code class="sourceCode python"><span class="kw">def</span> neighbours_swap(data, perm):
    <span class="co"># Returns the permutations corresponding to swapping every pair of jobs</span>
    candidates = [perm]
    <span class="kw">for</span> (i,j) in combinations(<span class="dt">range</span>(<span class="dt">len</span>(perm)), <span class="dv">2</span>):
        candidate = perm[:]
        candidate[i], candidate[j] = candidate[j], candidate[i]
        candidates.append(candidate)
    <span class="kw">return</span> candidates</code></pre>

<p>The next neighbourhood we consider uses information specific to the problem at hand. We find the jobs with the most idle time and consider swapping them in every way possible. We take in a value <code>size</code> which is the number of jobs we consider: the <code>size</code> most idle jobs. The first step in the process is to compute the idle time for every job in the permutation:</p>

<pre class="sourceCode python"><code class="sourceCode python"><span class="kw">def</span> neighbours_idle(data, perm, size=<span class="dv">4</span>):
    <span class="co"># Returns the permutations of the &lt;size&gt; most idle jobs</span>
    candidates = [perm]

    <span class="co"># Compute the idle time for each job</span>
    sol = flow.compile_solution(data, perm)
    results = []

    <span class="kw">for</span> i in <span class="dt">range</span>(<span class="dt">len</span>(data)):
        finish_time = sol[-<span class="dv">1</span>][i] + data[perm[i]][-<span class="dv">1</span>]
        idle_time = (finish_time - sol[<span class="dv">0</span>][i]) - <span class="dt">sum</span>([t <span class="kw">for</span> t in data[perm[i]]])
        results.append((idle_time, i))</code></pre>

<p>Next, we compute the list of <code>size</code> jobs that have the most idle time.</p>

<pre class="sourceCode python"><code class="sourceCode python">    <span class="co"># Take the &lt;size&gt; most idle jobs</span>
    subset = [job_ind <span class="kw">for</span> (idle, job_ind) in <span class="dt">reversed</span>(<span class="dt">sorted</span>(results))][:size]</code></pre>

<p>Finally, we construct the neighbourhood by considering every permutation of the most idle jobs that we have identified. To find the permutations, we make use of the <code>permutations</code> function from the <code>itertools</code> package.</p>

<pre class="sourceCode python"><code class="sourceCode python">    <span class="co"># Enumerate the permutations of the idle jobs</span>
    <span class="kw">for</span> ordering in permutations(subset):
        candidate = perm[:]
        <span class="kw">for</span> i in <span class="dt">range</span>(<span class="dt">len</span>(ordering)):
            candidate[subset[i]] = perm[ordering[i]]
        candidates.append(candidate)

    <span class="kw">return</span> candidates</code></pre>

<p>The final neighbourhood that we consider is commonly referred to as <em>Large Neighbourhood Search</em> (LNS). Intuitively, LNS works by considering small subsets of the current permutation in isolation—locating the best permutation of the subset of jobs gives us a single candidate for the LNS neighbourhood. By repeating this process for several (or all) subsets of a particular size, we can increase the number of candidates in the neighbourhood. We limit the number that are considered through the <code>MAX_LNS_NEIGHBOURHOODS</code> parameter, as the number of neighbours can grow quite quickly. The first step in the LNS computation is to compute the random list of job sets that we will consider swapping using the <code>combinations</code> function of the <code>itertools</code> package:</p>

<pre class="sourceCode python"><code class="sourceCode python"><span class="kw">def</span> neighbours_LNS(data, perm, size = <span class="dv">2</span>):
    <span class="co"># Returns the Large Neighbourhood Search neighbours</span>
    candidates = [perm]

    <span class="co"># Bound the number of neighbourhoods in case there are too many jobs</span>
    neighbourhoods = <span class="dt">list</span>(combinations(<span class="dt">range</span>(<span class="dt">len</span>(perm)), size))
    random.shuffle(neighbourhoods)</code></pre>

<p>Next, we iterate through the subsets to find the best permutation of jobs in each one. We have seen similar code above for iterating through all permutations of the most idle jobs. The key difference here is that we record only the best permutation for the subset, as the larger neighbourhood is constructed by choosing one permutation for each subset of the considered jobs.</p>

<pre class="sourceCode python"><code class="sourceCode python">    <span class="kw">for</span> subset in neighbourhoods[:flow.MAX_LNS_NEIGHBOURHOODS]:

        <span class="co"># Keep track of the best candidate for each neighbourhood</span>
        best_make = flow.makespan(data, perm)
        best_perm = perm

        <span class="co"># Enumerate every permutation of the selected neighbourhood</span>
        <span class="kw">for</span> ordering in permutations(subset):
            candidate = perm[:]
            <span class="kw">for</span> i in <span class="dt">range</span>(<span class="dt">len</span>(ordering)):
                candidate[subset[i]] = perm[ordering[i]]
            res = flow.makespan(data, candidate)
            <span class="kw">if</span> res &lt; best_make:
                best_make = res
                best_perm = candidate

        <span class="co"># Record the best candidate as part of the larger neighbourhood</span>
        candidates.append(best_perm)

    <span class="kw">return</span> candidates</code></pre>

<p>If we were to set the <code>size</code> parameter to be equal to the number of jobs, then every permutation would be considered and the best one selected. In practice, however, we need to limit the size of the subset to around 3 or 4; anything larger would cause the <code>neighbours_LNS</code> function to take a prohibitive amount of time.</p>

<h2 id="heuristics">Heuristics</h2>

<p>A heuristic returns a single candidate permutation from a set of provided candidates. The heuristic is also given access to the problem data in order to evaluate which candidate might be preferred.</p>

<p>The first heuristic that we consider is <code>heur_random</code>. This heuristic randomly selects a candidate from the list without evaluating which one might be preferred:</p>

<pre class="sourceCode python"><code class="sourceCode python"><span class="kw">def</span> heur_random(data, candidates):
    <span class="co"># Returns a random candidate choice</span>
    <span class="kw">return</span> random.choice(candidates)</code></pre>

<p>The next heuristic <code>heur_hillclimbing</code> uses the other extreme. Rather than randomly selecting a candidate, it selects the candidate that has the best makespan. Note that the list <code>scores</code> will contain tuples of the form <code>(make,perm)</code> where <code>make</code> is the makespan value for permutation <code>perm</code>. Sorting such a list places the tuple with the best makespan at the start of the list; from this tuple we return the permutation.</p>

<pre class="sourceCode python"><code class="sourceCode python"><span class="kw">def</span> heur_hillclimbing(data, candidates):
    <span class="co"># Returns the best candidate in the list</span>
    scores = [(flow.makespan(data, perm), perm) <span class="kw">for</span> perm in candidates]
    <span class="kw">return</span> <span class="dt">sorted</span>(scores)[<span class="dv">0</span>][<span class="dv">1</span>]</code></pre>

<p>The final heuristic, <code>heur_random_hillclimbing</code>, combines both the random and hillclimbing heuristics above. When performing local search, you may not always want to choose a random candidate, or even the best one. The <code>heur_random_hillclimbing</code> heuristic returns a &quot;pretty good&quot; solution by choosing the best candidate with probability 0.5, then the second best with probability 0.25, and so on. The while-loop essentially flips a coin at every iteration to see if it should continue increasing the index (with a limit on the size of the list). The final index chosen corresponds to the candidate that the heuristic selects.</p>

<pre class="sourceCode python"><code class="sourceCode python"><span class="kw">def</span> heur_random_hillclimbing(data, candidates):
    <span class="co"># Returns a candidate with probability proportional to its rank in sorted quality</span>
    scores = [(flow.makespan(data, perm), perm) <span class="kw">for</span> perm in candidates]
    i = <span class="dv">0</span>
    <span class="kw">while</span> (random.random() &lt; <span class="fl">0.5</span>) and (i &lt; <span class="dt">len</span>(scores) - <span class="dv">1</span>):
        i += <span class="dv">1</span>
    <span class="kw">return</span> <span class="dt">sorted</span>(scores)[i][<span class="dv">1</span>]</code></pre>

<p>Because makespan is the criteria that we are trying to optimize, hillclimbing will steer the local search process towards solutions with a better makespan. Introducing randomness allows us to explore the neighbourhood instead of going blindly towards the best-looking solution at every step.</p>

<h2 id="dynamic-strategy-selection">Dynamic Strategy Selection</h2>

<p>At the heart of the local search for a good permutation is the use of a particular heuristic and neighbourhood function to jump from one solution to another. How do we choose one set of options over another? In practice, it frequently pays off to switch strategies during the search. The dynamic strategy selection that we use will switch between combinations of heuristic and neighbourhood functions to try and shift dynamically to those strategies that work best. For us, a <em>strategy</em> is a particular configuration of heuristic and neighbourhood functions (including their parameter values.)</p>

<p>To begin, our code constructs the range of strategies that we want to consider during solving. In the strategy initialization, we use the <code>partial</code> function from the <code>functools</code> package to partially assign the parameters for each of the neighbourhoods. Additionally, we construct a list of the heuristic functions, and finally we use the product operator to add every combination of neighbourhood and heuristic function as a new strategy.</p>

<pre class="sourceCode python"><code class="sourceCode python"><span class="co">################</span>
<span class="co">## Strategies ##</span>
<span class="co">#################################################</span>
<span class="co">## A strategy is a particular configuration</span>
<span class="co">##  of neighbourhood generator (to compute</span>
<span class="co">##  the next set of candidates) and heuristic</span>
<span class="co">##  computation (to select the best candidate).</span>
<span class="co">##</span>

STRATEGIES = []

<span class="co"># Using a namedtuple is a little cleaner than using dictionaries.</span>
<span class="co">#  E.g., strategy[&#39;name&#39;] versus strategy.name</span>
Strategy = namedtuple(<span class="st">&#39;Strategy&#39;</span>, [<span class="st">&#39;name&#39;</span>, <span class="st">&#39;neighbourhood&#39;</span>, <span class="st">&#39;heuristic&#39;</span>])

<span class="kw">def</span> initialize_strategies():

    <span class="kw">global</span> STRATEGIES

    <span class="co"># Define the neighbourhoods (and parameters) that we would like to use</span>
    neighbourhoods = [
        (<span class="st">&#39;Random Permutation&#39;</span>, partial(neigh.neighbours_random, num=<span class="dv">100</span>)),
        (<span class="st">&#39;Swapped Pairs&#39;</span>, neigh.neighbours_swap),
        (<span class="st">&#39;Large Neighbourhood Search (2)&#39;</span>, partial(neigh.neighbours_LNS, size=<span class="dv">2</span>)),
        (<span class="st">&#39;Large Neighbourhood Search (3)&#39;</span>, partial(neigh.neighbours_LNS, size=<span class="dv">3</span>)),
        (<span class="st">&#39;Idle Neighbourhood (3)&#39;</span>, partial(neigh.neighbours_idle, size=<span class="dv">3</span>)),
        (<span class="st">&#39;Idle Neighbourhood (4)&#39;</span>, partial(neigh.neighbours_idle, size=<span class="dv">4</span>)),
        (<span class="st">&#39;Idle Neighbourhood (5)&#39;</span>, partial(neigh.neighbours_idle, size=<span class="dv">5</span>))
    ]

    <span class="co"># Define the heuristics that we would like to use</span>
    heuristics = [
        (<span class="st">&#39;Hill Climbing&#39;</span>, heur.heur_hillclimbing),
        (<span class="st">&#39;Random Selection&#39;</span>, heur.heur_random),
        (<span class="st">&#39;Biased Random Selection&#39;</span>, heur.heur_random_hillclimbing)
    ]

    <span class="co"># Combine every neighbourhood and heuristic strategy</span>
    <span class="kw">for</span> (n, h) in product(neighbourhoods, heuristics):
        STRATEGIES.append(Strategy(<span class="st">&quot;</span><span class="ot">%s</span><span class="st"> / </span><span class="ot">%s</span><span class="st">&quot;</span> % (n[<span class="dv">0</span>], h[<span class="dv">0</span>]), n[<span class="dv">1</span>], h[<span class="dv">1</span>]))</code></pre>

<p>Once the strategies are defined, we do not necessarily want to stick with a single option during search. Instead, we select randomly any one of the strategies, but <em>weight the selection</em> based on how well the strategy has performed. We describe the weighting below, but for the <code>pick_strategy</code> function, we need only a list of strategies and a corresponding list of relative weights (any number will do). To select a random strategy with the given weights, we pick a number uniformly between 0 and the sum of all weights. Subsequently, we find the lowest index <span class="math">\(i\)</span> such that the sum of all of the weights for indices smaller than <span class="math">\(i\)</span> is greater than the random number that we have chosen. This technique, sometimes referred to as <em>roulette wheel selection</em>, will randomly pick a strategy for us and give a greater chance to those strategies with higher weight.</p>

<pre class="sourceCode python"><code class="sourceCode python"><span class="kw">def</span> pick_strategy(strategies, weights):
    <span class="co"># Picks a random strategy based on its weight: roulette wheel selection</span>
    <span class="co">#  Rather than selecting a strategy entirely at random, we bias the</span>
    <span class="co">#  random selection towards strategies that have worked well in the</span>
    <span class="co">#  past (according to the weight value).</span>
    total = <span class="dt">sum</span>([weights[strategy] <span class="kw">for</span> strategy in strategies])
    pick = random.uniform(<span class="dv">0</span>, total)
    count = weights[strategies[<span class="dv">0</span>]]

    i = <span class="dv">0</span>
    <span class="kw">while</span> pick &gt; count:
        count += weights[strategies[i<span class="dv">+1</span>]]
        i += <span class="dv">1</span>

    <span class="kw">return</span> strategies[i]</code></pre>

<p>What remains is to describe how the weights are augmented during the search for a solution. This occurs in the main while loop of the solver at regularly timed intervals (defined with the <code>TIME_INCREMENT</code> variable):</p>

<pre class="sourceCode python"><code class="sourceCode python">
        <span class="co"># At regular intervals, switch the weighting on the strategies available.</span>
        <span class="co">#  This way, the search can dynamically shift towards strategies that have</span>
        <span class="co">#  proven more effective recently.</span>
        <span class="kw">if</span> time.time() &gt; time_last_switch + TIME_INCREMENT:

            time_last_switch = time.time()</code></pre>

<p>Recall that <code>strat_improvements</code> stores the sum of all improvements that a strategy has made while <code>strat_time_spent</code> stores the time that the strategy has been given during the last interval. We normalize the improvements made by the total time spent for each strategy to get a metric of how well each strategy has performed in the last interval. Because a strategy may not have had a chance to run at all, we choose a small amount of time as a default value.</p>

<pre class="sourceCode python"><code class="sourceCode python">            <span class="co"># Normalize the improvements made by the time it takes to make them</span>
            results = <span class="dt">sorted</span>([
                (<span class="dt">float</span>(strat_improvements[s]) / <span class="dt">max</span>(<span class="fl">0.001</span>, strat_time_spent[s]), s)
                <span class="kw">for</span> s in STRATEGIES])</code></pre>

<p>Now that we have a ranking of how well each strategy has performed, we add <span class="math">\(k\)</span> to the weight of the best strategy (assuming we had <span class="math">\(k\)</span> strategies), <span class="math">\(k-1\)</span> to the next best strategy, etc. Each strategy will have its weight increased, and the worst strategy in the list will see an increase of only 1.</p>

<pre class="sourceCode python"><code class="sourceCode python">            <span class="co"># Boost the weight for the successful strategies</span>
            <span class="kw">for</span> i in <span class="dt">range</span>(<span class="dt">len</span>(STRATEGIES)):
                strat_weights[results[i][<span class="dv">1</span>]] += <span class="dt">len</span>(STRATEGIES) - i</code></pre>

<p>As an extra measure, we artificially bump up all of the strategies that were not used. This is done so that we do not forget about a strategy entirely. While one strategy may appear to perform badly in the beginning, later in the search it can prove quite useful.</p>

<pre class="sourceCode python"><code class="sourceCode python">                <span class="co"># Additionally boost the unused strategies to avoid starvation</span>
                <span class="kw">if</span> results[i][<span class="dv">0</span>] == <span class="dv">0</span>:
                    strat_weights[results[i][<span class="dv">1</span>]] += <span class="dt">len</span>(STRATEGIES)</code></pre>

<p>Finally, we output some information about the strategy ranking (if the <code>DEBUG_SWITCH</code> flag is set), and we reset the <code>strat_improvements</code> and <code>strat_time_spent</code> variables for the next interval.</p>

<pre class="sourceCode python"><code class="sourceCode python">            <span class="kw">if</span> DEBUG_SWITCH:
                <span class="dt">print</span> <span class="st">&quot;</span><span class="ch">\n</span><span class="st">Computing another switch...&quot;</span>
                <span class="dt">print</span> <span class="st">&quot;Best: </span><span class="ot">%s</span><span class="st"> (</span><span class="ot">%d</span><span class="st">)&quot;</span> % (results[<span class="dv">0</span>][<span class="dv">1</span>].name, results[<span class="dv">0</span>][<span class="dv">0</span>])
                <span class="dt">print</span> <span class="st">&quot;Worst: </span><span class="ot">%s</span><span class="st"> (</span><span class="ot">%d</span><span class="st">)&quot;</span> % (results[-<span class="dv">1</span>][<span class="dv">1</span>].name, results[-<span class="dv">1</span>][<span class="dv">0</span>])
                <span class="dt">print</span> results
                <span class="dt">print</span> <span class="dt">sorted</span>([strat_weights[STRATEGIES[i]] 
                              <span class="kw">for</span> i in <span class="dt">range</span>(<span class="dt">len</span>(STRATEGIES))])

            strat_improvements = {strategy: <span class="dv">0</span> <span class="kw">for</span> strategy in STRATEGIES}
            strat_time_spent = {strategy: <span class="dv">0</span> <span class="kw">for</span> strategy in STRATEGIES}</code></pre>

<h2 id="discussion">Discussion</h2>

<p>In this chapter we have seen what can be accomplished with a relatively small amount of code to solve the complex optimization problem of flow shop scheduling. Finding the best solution to a large optimization problem such as the flow shop can be difficult. In a case like this, we can turn to approximation techniques such as local search to compute a solution that is <em>good enough</em>. With local search we can move from one solution to another, aiming to find one of good quality.</p>

<p>The general intuition behind local search can be applied to a wide range of problems. We focused on (1) generating a neighbourhood of related solutions to a problem from one candidate solution, and (2) establishing ways to evaluate and compare solutions. With these two components in hand, we can use the local search paradigm to find a valuable solution when the best option is simply too difficult to compute.</p>

<p>Rather than using any one strategy to solve the problem, we saw how a strategy can be chosen dynamically to shift during the solving process. This simple and powerful technique gives the program the ability to mix and match partial strategies for the problem at hand, and it also means that the developer does not have to hand-tailor the strategy.</p>
  </body>
</html>
